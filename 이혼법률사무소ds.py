# -*- coding: utf-8 -*-
"""ì´í˜¼ë²•ë¥ ì‚¬ë¬´ì†ŒDS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FQyFEs1USBVM2cMxYJ-569f8Mkq7AXa4

# **ì• ë§¤ëª¨í˜¸í•œ ë³€ìˆ˜ ì œê±°, ë¶€ì • -> ê¸ì •ìœ¼ë¡œ ë°”ê¾¼ ì—‘ì…€ íŒŒì¼**
- 11/10 (ì›”)
"""

# ==========================================================
# Divorce.xlsx - ì¼ë¶€ ë¶€ì •ë¬¸ë§Œ ì²™ë„ ë°˜ì „ + ì¼ë¶€ ë³€ìˆ˜ ì‚­ì œ
# ==========================================================

import pandas as pd
from google.colab import files

# 1ï¸âƒ£ divorce.xlsx ì—…ë¡œë“œ
print("ğŸ“‚ 'divorce.xlsx' íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded = files.upload()  # ì—…ë¡œë“œ ì°½ì´ ëœ¸

# 2ï¸âƒ£ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel('/content/divorce.xlsx')
print("âœ… íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ:", df.shape)

# 3ï¸âƒ£ ì—­ì½”ë”©(ì²™ë„ ë°˜ì „)í•  ë¬¸í•­ ë²ˆí˜¸
reverse_items = [6,7,31,32,33,34,36,37,39,40,41,42]

# 4ï¸âƒ£ ì‚­ì œí•  ë¬¸í•­ ë²ˆí˜¸
delete_items = [4,35,43,44,45,47,50,51,52,53,54]

# 5ï¸âƒ£ ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜ (Atr1~Atr54 í˜•íƒœ)
reverse_cols = [f"Atr{i}" for i in reverse_items if f"Atr{i}" in df.columns]
delete_cols = [f"Atr{i}" for i in delete_items if f"Atr{i}" in df.columns]

print("\nğŸ” ì—­ì½”ë”© ëŒ€ìƒ:", reverse_cols)
print("ğŸ—‘ï¸ ì‚­ì œ ëŒ€ìƒ:", delete_cols)

# 6ï¸âƒ£ ì—­ì½”ë”© ì‹¤í–‰ (0~4 ì²™ë„ â†’ 4 - X)
df[reverse_cols] = 4 - df[reverse_cols]

# 7ï¸âƒ£ ë¶ˆí•„ìš”í•œ ì—´ ì‚­ì œ
df = df.drop(columns=delete_cols, errors='ignore')

# 8ï¸âƒ£ ê²°ê³¼ ì €ì¥
output_file = "divorce_revised_selected.xlsx"
df.to_excel(output_file, index=False)

print(f"\nâœ… ìƒˆ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}")
print("ğŸ“¥ Colab ì™¼ìª½ 'íŒŒì¼' íƒ­ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

"""# ë³€ìˆ˜ ì¤‘ìš”ë„
- ìˆ˜ì •í•œ ì—‘ì…€ íŒŒì¼ì˜ ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶œë ¥
- 11/10 (ì›”)
"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (Load data)
df = pd.read_excel("divorce_revised_selected.xlsx")

# 2. ì…ë ¥(X)ê³¼ ì¶œë ¥(y) êµ¬ë¶„ (Separate X and y)
y = df['Class']
X = df.drop(columns=['Class'])

# 3. ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (Train Random Forest Classifier Model)
rf = RandomForestClassifier(n_estimators=128, random_state=42)
rf.fit(X, y)

# 4. ë³€ìˆ˜ ì¤‘ìš”ë„ ê³„ì‚° (MDI ë°©ì‹) (Calculate Feature Importance using MDI)
importances = pd.Series(rf.feature_importances_, index=X.columns)

# 5. ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™” (Visualize Feature Importance)
top_n = 21 # ìƒìœ„ 21ê°œë§Œ í‘œì‹œ
plt.figure(figsize=(10, 8), dpi=1000)
# ìƒìœ„ 21ê°œ ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”
importances.sort_values().tail(top_n).plot.barh(color='skyblue')
plt.title(f'Feature Importance (MDI) for Divorce Prediction (Top {top_n} features)')
plt.xlabel('Mean Decrease Impurity (MDI)')
plt.ylabel('Feature')
plt.grid(axis='x', linestyle='--')

# íŒŒì¼ ì €ì¥ ëª…ë ¹ ì œê±° ë° í™”ë©´ ì¶œë ¥ë§Œ ìœ ì§€
plt.show()

"""# **ì‹œê°í™” - í•œê²°**

# **1. ì›Œë“œ í´ë¼ìš°ë“œ**
"""

# 1. Java ì„¤ì¹˜ (KoNLPyìš©)
!apt-get update -qq
!apt-get install -y openjdk-11-jdk -qq > /dev/null

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"

# 2. KoNLPy ë° JPype1 ì„¤ì¹˜
!pip install konlpy JPype1 -qq

# 3. í•œê¸€ í°íŠ¸ ì„¤ì¹˜ (ì›Œë“œí´ë¼ìš°ë“œìš©)
!apt-get install -y fonts-nanum -qq > /dev/null
!fc-cache -fv  # í°íŠ¸ ìºì‹œ ê°±ì‹ 

# 4. í°íŠ¸ ë§¤ë‹ˆì € ë¦¬ë¹Œë“œ
import matplotlib.font_manager as fm

# -*- coding: utf-8 -*-
import matplotlib.pyplot as plt
from konlpy.tag import Okt
from wordcloud import WordCloud

# ì„¤ë¬¸ ë¬¸í•­ ë¦¬ìŠ¤íŠ¸
sentences = [
    "ì•„ë‚´ì™€ ë‚˜ëŠ” ì‹ ë¢°ì— ëŒ€í•œ ê°€ì¹˜ë¥¼ ê°€ì§„ë‹¤.",
    "ì•„ë‚´ì™€ ì €ëŠ” ê²°í˜¼ ìƒí™œì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•˜ë‹¤.",
    "ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œê¸°ë„ ì „ì— ìš°ë¦¬ëŠ” ë§‰ ì‹¸ì›€ì„ ì‹œì‘í•˜ê³  ìˆì§€ ì•ŠëŠ”ë‹¤.",
    "ì–¸ì  ê°€ ë¯¸ë˜ì— ë’¤ëŒì•„ë³¼ ë•Œ ì•„ë‚´ì™€ ë‚˜ëŠ” ì„œë¡œ ì¡°í™”ë¥¼ ì´ë£¨ê³  ìˆë‹¤ê³  ìƒê°í•œë‹¤.",
    "ìš°ë¦¬ëŠ” ì‚¶ì—ì„œ í–‰ë³µí•´ì§€ëŠ” ê²ƒì— ëŒ€í•´ ì•„ë‚´ì™€ ì¼ì¹˜í•˜ëŠ” ê²¬í•´ë¥¼ ê³µìœ í•œë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ì™€ í•¨ê»˜ ì—¬í–‰í•˜ëŠ” ê²ƒì„ ì¦ê¸´ë‹¤.",
    "ì•„ë‚´ì™€ ë‚˜ëŠ” ê²°í˜¼ ìƒí™œì—ì„œ ì—­í• ì´ ì–´ë– í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•˜ë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ì˜ ê¸°ë³¸ì ì¸ ê±±ì •ê±°ë¦¬ë¥¼ ì•Œê³  ìˆë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ì˜ ë‚´ë©´ ì„¸ê³„ë¥¼ ì•Œê³  ìˆë‹¤.",
    "ìš°ë¦¬ëŠ” ì‚¬ë‘ì´ ì–´ë– í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•´ ì•„ë‚´ì™€ ì˜ê²¬ì´ ì¼ì¹˜í•œë‹¤.",
    "ì•„ë‚´ì™€ í•¨ê»˜ ì‚´ê³  ì‹¶ë‹¤ëŠ” ê¿ˆì€ ë¹„ìŠ·í•˜ê³  ì¡°í™”ë¡­ë‹¤.",
    "ìš°ë¦¬ê°€ ì‚¬ëŒ(ìë…€, ì¹œêµ¬ ë“±)ì— ëŒ€í•´ ê°–ëŠ” ëª©í‘œëŠ” ëŒ€ë¶€ë¶„ ê°™ë‹¤.",
    "ì‹¸ì›€ì€ ì£¼ ê°‘ìê¸° ì¼ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤.",
    "ë‚˜ëŠ” ìš°ë¦¬ê°€ ë…¼ìŸí•  ë•Œ êµ´ìš•ê°ì„ ì¤„ ìˆ˜ ì—†ë‹¤.",
    "ì•„ë‚´ì™€ ë‚˜ëŠ” ê°œì¸ì˜ ììœ  ì¸¡ë©´ì—ì„œ ë¹„ìŠ·í•œ ê°€ì¹˜ê´€ì„ ê°€ì§€ê³  ìˆë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ì™€ í•¨ê»˜ íœ´ê°€ë¥¼ ì¦ê¸´ë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ì˜ ì¹œêµ¬ë“¤ê³¼ ê·¸ë“¤ì˜ ì‚¬íšŒì  ê´€ê³„ë¥¼ ì¸ì§€í•˜ê³  ìˆë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ê°€ í˜„ì¬ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ëŠ” ì›ì¸ì´ ë¬´ì—‡ì¸ì§€ ì¸ì§€í•˜ê³  ìˆë‹¤.",
    "ë‚´ê°€ ì•„ë‚´ì™€ ë¬´ì–¸ê°€ì— ëŒ€í•´ ì´ì•¼ê¸°í•  ë•Œ, ë‚´ ì°¨ë¶„í•¨ì€ ìœ ì§€ëœë‹¤.",
    "ë‚˜ëŠ” ì•„ë‚´ì˜ í¬ë§ê³¼ ë°”ëŒì„ ì¸ì§€í•˜ê³  ìˆë‹¤.",
    "ë‚´ ì•„ë‚´ì™€ì˜ ë…¼ìŸì€ ì°¨ë¶„í•˜ë‹¤."
]

# í…ìŠ¤íŠ¸ ê²°í•©
text = " ".join(sentences)

# í˜•íƒœì†Œ ë¶„ì„ ë° ëª…ì‚¬ ì¶”ì¶œ
okt = Okt()
nouns = okt.nouns(text)


# ê¸€ì ìˆ˜ 2ê°œ ì´ìƒì¸ ë‹¨ì–´ë§Œ ì¶”ì¶œ (ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì œê±°)
filtered_nouns = [word for word in nouns if len(word) >= 2]

stopwords = [
    "ëŒ€í•´", "ëŒ€í•œ", "ë¬´ì—‡", "ë¬´ìŠ¨", "ê°€ì§€", "ê°™ë‹¤", "ìˆë‹¤", "í•˜ë‹¤", "ë˜ë‹¤", "ì—ì„œ", "ì—ê²Œ", "ìœ¼ë¡œ",
    "ê·¸ë¦¬ê³ ", "ì´ë‹¤", "ì•„ë‹ˆë‹¤", "ë‚´", "ì €", "ë‚˜", "ë“±", "ë•Œ", "ì¼", "ìœ„í•´", "ì ", "ì•ˆ", "ìˆ˜","ì•„ë‚´", "ê²°í˜¼", "ìš°ë¦¬"
]

# ë¶ˆìš©ì–´ ì œê±° ë° ê¸€ì ìˆ˜ 2ê°œ ì´ìƒ í•„í„°ë§ì„ ê²°í•©í•˜ì—¬ ì ìš©
filtered_nouns = [
    word for word in nouns
    if word not in stopwords and len(word) >= 2
]

# ë‹¨ì–´ ì—°ê²°
joined_text = " ".join(filtered_nouns)

# ìƒ‰ìƒ í•¨ìˆ˜ (í° ë‹¨ì–´ëŠ” ì§„í•œ íŒŒë‘, ì‘ì€ ë‹¨ì–´ëŠ” í•˜ëŠ˜ìƒ‰)
def blue_gradient_color_func(word, font_size, position, orientation, random_state=None, **kwargs):
    # font_sizeê°€ í´ìˆ˜ë¡ ì§„í•œ íŒŒë‘ (hslì˜ ë°ê¸°ê°’ ë‚®ì¶¤)
    # ê¸€ì í¬ê¸°ì— ë”°ë¼ ë°ê¸°(lightness)ë¥¼ 90%ì—ì„œ 25%ê¹Œì§€ ì¡°ì ˆ
    lightness = max(25, 90 - font_size / 2)
    return f"hsl(210, 90%, {lightness}%)"

# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
# font_pathëŠ” ì‹œìŠ¤í…œ í™˜ê²½ì— ë”°ë¼ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
wordcloud = WordCloud(
    font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
    background_color='white',
    width=1600,
    height=1000,
    color_func=blue_gradient_color_func,
    prefer_horizontal=0.95,
    max_words=150,
    min_font_size=10,
    max_font_size=250,
    collocations=False,
    relative_scaling=0.15,
    scale=3,
    margin=5
).generate(joined_text)

# ì‹œê°í™”
plt.figure(figsize=(14, 9),dpi=1000)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

# ì •ì œëœ ë‹¨ì–´ ì˜ˆì‹œ ì¶œë ¥ (ì°¸ê³ ìš©)
print("--- ì •ì œëœ ë‹¨ì–´ ëª©ë¡ ì˜ˆì‹œ (ê¸€ì ìˆ˜ 2ê°œ ì´ìƒ) ---")
print(filtered_nouns[:100])

"""# **ğŸ¥‡ Top 5 í•µì‹¬ í‚¤ì›Œë“œ (ê°€ì¥ ì¤‘ìš”í•œ ìš”ì†Œ)**
1. ë…¼ìŸ
2. ì‹ ë¢°
3. ìƒê°
4. ì‹¸ì›€
5. ìƒí™œ

# **2. íˆíŠ¸ë§µ**
"""

!sudo apt-get install -y fonts-nanum > /dev/null
!sudo fc-cache -fv
!rm -rf ~/.cache/matplotlib

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import numpy as np
from matplotlib.colors import LinearSegmentedColormap, PowerNorm

# âœ… Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    plt.rc('font', family='NanumGothic')
    plt.rcParams['axes.unicode_minus'] = False
except:
    plt.rcParams['axes.unicode_minus'] = False

# ì„¤ë¬¸ ë¬¸í•­ ë¦¬ìŠ¤íŠ¸ (ë¼ë²¨ë¡œ ì‚¬ìš©)
heatmap_features = [
    'Atr8','Atr9','Atr11','Atr12','Atr14','Atr15','Atr16','Atr17','Atr18','Atr19',
    'Atr20','Atr25','Atr26','Atr27','Atr28','Atr30','Atr36','Atr37','Atr39','Atr40','Atr41'
]

# íŒŒì¼ ì—…ë¡œë“œ
print("'divorce_revised_selected_upper.xlsx' íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded = files.upload()

df = pd.read_excel('/content/divorce_revised_selected_upper.xlsx')

# ë°ì´í„°ì…‹ì— ì¡´ì¬í•˜ëŠ” ë³€ìˆ˜ë§Œ ì‚¬ìš©
valid_features = [col for col in heatmap_features if col in df.columns]
if not valid_features:
    raise SystemExit("âš  ë°ì´í„°ì…‹ì— í•´ë‹¹ ë³€ìˆ˜ ì—†ìŒ")

# ìƒê´€ê³„ìˆ˜ ê³„ì‚°
corr_matrix = df[valid_features].corr()

# ë²ˆí˜¸ ë§¤í•‘ ì‚­ì œ â†’ Atr8, Atr9 ê·¸ëŒ€ë¡œ ì‚¬ìš©
corr_matrix.index = valid_features
corr_matrix.columns = valid_features

# íŒŒìŠ¤í…” Blueâ€“Pink íŒ”ë ˆíŠ¸
blue_light  = "#eef6ff"
blue_medium = "#bcd8ff"
blue_dark   = "#7fb3ff"

pink_light  = "#fff5fa"
pink_medium = "#ffd6e8"
pink_dark   = "#ff99c2"

colors = [
    blue_dark, blue_medium, blue_light,
    pink_light, pink_medium, pink_dark
]

cmap = LinearSegmentedColormap.from_list("pastel_bluepink_best", colors)
norm = PowerNorm(gamma=0.6)

# í´ëŸ¬ìŠ¤í„° íˆíŠ¸ë§µ ìƒì„±
g = sns.clustermap(
    corr_matrix,
    cmap=cmap,
    norm=norm,
    linewidths=.4,
    figsize=(15, 15),
    row_cluster=False,
    col_cluster=False,
)

# yì¶• ë¼ë²¨ (Atr ê·¸ëŒ€ë¡œ)
g.ax_heatmap.set_yticklabels(
    g.ax_heatmap.get_ymajorticklabels(),
    rotation=0,
    fontsize=16
)

# xì¶• ë¼ë²¨ (Atr ê·¸ëŒ€ë¡œ)
g.ax_heatmap.set_xticklabels(
    g.ax_heatmap.get_xmajorticklabels(),
    rotation=45,
    fontsize=14
)

# íˆíŠ¸ë§µ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
heatmap_pos = g.ax_heatmap.get_position()

# ğŸ› ì»¬ëŸ¬ë°” ìœ„ì¹˜ ì¡°ì •
cbar_width = 0.015
spacing = 0.04

g.cax.set_position([
    heatmap_pos.x0 - cbar_width - spacing,
    heatmap_pos.y0,
    cbar_width,
    heatmap_pos.height
])
g.cax.tick_params(labelsize=14)

# ğŸ· ì œëª©
g.fig.text(
    (heatmap_pos.x0 + heatmap_pos.x1) / 2,
    heatmap_pos.y1 + 0.02,
    "ì„¤ë¬¸ ë¬¸í•­ ê°„ ìƒê´€ê´€ê³„ í´ëŸ¬ìŠ¤í„° íˆíŠ¸ë§µ",
    ha='center',
    va='bottom',
    fontsize=35,
    fontweight='bold'
)

plt.show()
plt.savefig("heatmap_highres.png", dpi=400, bbox_inches='tight')

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import numpy as np

# Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    plt.rc('font', family='NanumGothic')
    plt.rcParams['axes.unicode_minus'] = False
except:
    plt.rcParams['axes.unicode_minus'] = False


# âœ… ì„¤ë¬¸ ë¬¸í•­ ë§¤í•‘
QUESTION_MAP = {
    'Atr8': 'ë‚˜ëŠ” ì•„ë‚´ì™€ í•¨ê»˜ íœ´ê°€ë¥¼ ì¦ê¸´ë‹¤.',
    'Atr9': 'ë‚˜ëŠ” ì•„ë‚´ì™€ í•¨ê»˜ ì—¬í–‰í•˜ëŠ” ê²ƒì„ ì¦ê¸´ë‹¤.',
    'Atr11': 'ì–¸ì  ê°€ ë¯¸ë˜ì— ë’¤ëŒì•„ë³¼ ë•Œ ì•„ë‚´ì™€ ë‚˜ëŠ” ì„œë¡œ ì¡°í™”ë¥¼ ì´ë£¨ê³  ìˆë‹¤ê³  ìƒê°í•œë‹¤.',
    'Atr12': 'ì•„ë‚´ì™€ ë‚˜ëŠ” ê°œì¸ì˜ ììœ  ì¸¡ë©´ì—ì„œ ë¹„ìŠ·í•œ ê°€ì¹˜ê´€ì„ ê°€ì§€ê³  ìˆë‹¤.',
    'Atr14': 'ìš°ë¦¬ê°€ ì‚¬ëŒ(ìë…€, ì¹œêµ¬ ë“±)ì— ëŒ€í•´ ê°–ëŠ” ëª©í‘œëŠ” ëŒ€ë¶€ë¶„ ê°™ë‹¤.',
    'Atr15': 'ì•„ë‚´ì™€ í•¨ê»˜ ì‚´ê³  ì‹¶ë‹¤ëŠ” ê¿ˆì€ ë¹„ìŠ·í•˜ê³  ì¡°í™”ë¡­ë‹¤.',
    'Atr16': 'ìš°ë¦¬ëŠ” ì‚¬ë‘ì´ ì–´ë– í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•´ ì•„ë‚´ì™€ ì˜ê²¬ì´ ì¼ì¹˜í•œë‹¤.',
    'Atr17': 'ìš°ë¦¬ëŠ” ì‚¶ì—ì„œ í–‰ë³µí•´ì§€ëŠ” ê²ƒì— ëŒ€í•´ ì•„ë‚´ì™€ ê°™ì€ ê²¬í•´ë¥¼ ê³µìœ í•œë‹¤.',
    'Atr18': 'ì•„ë‚´ì™€ ì €ëŠ” ê²°í˜¼ ìƒí™œì´ ì–´ë– í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•œë‹¤.',
    'Atr19': 'ì•„ë‚´ì™€ ì €ëŠ” ê²°í˜¼ ìƒí™œì—ì„œ ì—­í• ì´ ì–´ë– í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•˜ë‹¤.',
    'Atr20': 'ì•„ë‚´ì™€ ì €ëŠ” ì‹ ë¢°ì— ëŒ€í•œ ê°€ì¹˜ê°€ ë¹„ìŠ·í•˜ë‹¤.',
    'Atr25': 'ì €ëŠ” ì•„ë‚´ì˜ ë‚´ë©´ ì„¸ê³„ë¥¼ ì•Œê³  ìˆë‹¤.',
    'Atr26': 'ì•„ë‚´ì˜ ê¸°ë³¸ì ì¸ ê±±ì •ê±°ë¦¬ë¥¼ ì•Œê³  ìˆë‹¤.',
    'Atr27': 'ì €ëŠ” ì•„ë‚´ê°€ í˜„ì¬ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ëŠ” ì›ì¸ì´ ë¬´ì—‡ì¸ì§€ ì•Œê³  ìˆë‹¤.',
    'Atr28': 'ë‚˜ëŠ” ì•„ë‚´ì˜ í¬ë§ê³¼ ë°”ëŒì„ ì•ˆë‹¤.',
    'Atr30': 'ë‚˜ëŠ” ì•„ë‚´ì˜ ì¹œêµ¬ë“¤ê³¼ ê·¸ë“¤ì˜ ì‚¬íšŒì  ê´€ê³„ë¥¼ ì•ˆë‹¤.',
    'Atr36': 'ë‚˜ëŠ” ìš°ë¦¬ê°€ ë…¼ìŸí•  ë•Œ êµ´ìš•ê°ì„ ì¤„ ìˆ˜ ì—†ë‹¤.',
    'Atr37': 'ë‚´ ì•„ë‚´ì™€ì˜ ë…¼ìŸì€ ì°¨ë¶„í•˜ë‹¤.',
    'Atr39': 'ì‹¸ì›€ì´ ê°‘ìê¸° ì¼ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤.',
    'Atr40': 'ë‚˜ëŠ” ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œê¸°ë„ ì „ì— ìš°ë¦¬ëŠ” ì‹¸ì›€ì„ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.',
    'Atr41': 'ë‚´ê°€ ì•„ë‚´ì™€ ë¬´ì–¸ê°€ì— ëŒ€í•´ ì´ì•¼ê¸°í•  ë•Œ, ë‚´ ì°¨ë¶„í•¨ì€ ìœ ì§€ëœë‹¤.',
}

heatmap_features = list(QUESTION_MAP.keys())

print("'divorce_revised_selected_upper.xlsx' íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded = files.upload()

df = pd.read_excel('/content/divorce_revised_selected_upper.xlsx')

valid_features = [col for col in heatmap_features if col in df.columns]
if not valid_features:
    raise SystemExit("âš  ë°ì´í„°ì…‹ì— í•´ë‹¹ ë³€ìˆ˜ ì—†ìŒ")

corr_matrix = df[valid_features].corr()

filtered_map = {k: v for k, v in QUESTION_MAP.items() if k in valid_features}
corr_matrix.index = corr_matrix.index.map(filtered_map)
corr_matrix.columns = corr_matrix.columns.map(filtered_map)

# clustermap ìƒì„± (colorbar ê¸°ë³¸ ìœ„ì¹˜ë¡œ ë§Œë“  ë’¤ ì´ë™)
g = sns.clustermap(
    corr_matrix,
    cmap='coolwarm',
    annot=False,
    linewidths=.4,
    figsize=(15, 15),
    row_cluster=False,
    col_cluster=False,
)

# íˆíŠ¸ë§µ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
heatmap_pos = g.ax_heatmap.get_position()

# ì»¬ëŸ¬ë°” ìœ„ì¹˜
cbar_width = 0.015  # ì»¬ëŸ¬ë°” ë‘ê»˜
spacing = 0.04     # íˆíŠ¸ë§µê³¼ ì»¬ëŸ¬ë°” ê°„ ìµœì†Œ ê°„ê²©

g.cax.set_position([
    heatmap_pos.x0 - cbar_width - spacing,
    heatmap_pos.y0,
    cbar_width,
    heatmap_pos.height
])

# ì œëª© ìœ„ì¹˜
g.fig.text(
    (heatmap_pos.x0 + heatmap_pos.x1) / 2,
    heatmap_pos.y1 + 0.02,
    "ì„¤ë¬¸ ë¬¸í•­ ê°„ ìƒê´€ê´€ê³„ í´ëŸ¬ìŠ¤í„° íˆíŠ¸ë§µ",
    ha='center',
    va='bottom',
    fontsize=24,
    fontweight='bold'
)

plt.show()

"""# **ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ ë¶„ì„**
1. ìœ ì‚¬ì„± ë° ì¡°í™”:
  - Atr15(í•¨ê»˜ ì‚´ê³  ì‹¶ì€ ê¿ˆ), Atr17(ì‚¶ì˜ í–‰ë³µ ê²¬í•´ ê³µìœ ), Atr11(ë¯¸ë˜ì— ì¡°í™”ë¥¼ ì´ë£¸), Atr12(ê°œì¸ì˜ ììœ  ê°€ì¹˜ê´€ ìœ ì‚¬)
  - ë¯¸ë˜ì— ëŒ€í•œ ê³µë™ì˜ ë¹„ì „ê³¼ í•µì‹¬ ê°€ì¹˜ê´€ì˜ ìœ ì‚¬ì„±
2. ì†Œí†µ ë° ì´í•´
  - Atr25(ì•„ë‚´ì˜ ë‚´ë©´ ì„¸ê³„), Atr28(ì•„ë‚´ì˜ í¬ë§ê³¼ ë°”ëŒ), Atr27(ì•„ë‚´ì˜ ìŠ¤íŠ¸ë ˆìŠ¤ ì›ì¸), Atr26(ì•„ë‚´ì˜ ê¸°ë³¸ì ì¸ ê±±ì •ê±°ë¦¬)
  - ë°°ìš°ìì˜ ë‚´ë©´ì ì¸ ê°ì •, í¬ë§, ê·¸ë¦¬ê³  ì–´ë ¤ì›€(ìŠ¤íŠ¸ë ˆìŠ¤)ì„ ì´í•´í•˜ëŠ” ì‹¬ì¸µì ì¸ ìš”ì†Œ ë¬¸í•­
3. ì°¨ë¶„í•œ ë…¼ìŸ
  - Atr37(ë…¼ìŸì€ ì°¨ë¶„í•˜ë‹¤), Atr41(ì´ì•¼ê¸°í•  ë•Œ ì°¨ë¶„í•¨ ìœ ì§€), Atr39(ì‹¸ì›€ì´ ê°‘ìê¸° ì¼ì–´ë‚˜ì§€ ì•ŠìŒ)
  - ë…¼ìŸê³¼ ê°ˆë“± ìƒí™©ì„ ì°¨ë¶„í•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•˜ê²Œ ê´€ë¦¬í•˜ëŠ” ëŠ¥ë ¥
  - ê°ˆë“± íšŒí”¼ê°€ ì•„ë‹ˆë¼ ê°ˆë“± ê´€ë¦¬ ëŠ¥ë ¥ì´ ë§Œì¡±ë„ë¥¼ ë†’ì´ëŠ” ìš”ì†Œ

# **ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„**
- 'ë‚˜ëŠ” ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œê¸°ë„ ì „ì— ìš°ë¦¬ëŠ” ì‹¸ì›€ì„ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.'<->'ì–¸ì  ê°€ ë¯¸ë˜ì— ë’¤ëŒì•„ë³¼ ë•Œ ì•„ë‚´ì™€ ë‚˜ëŠ” ì„œë¡œ ì¡°í™”ë¥¼ ì´ë£¨ê³  ìˆë‹¤ê³  ìƒê°í•œë‹¤.'
  -> ì‹¸ì›€ì´ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•´ì§ˆìˆ˜ë¡ ì—­ì„¤ì ìœ¼ë¡œ ì¥ê¸°ì  ì¡°í™”ê°€ ìˆë‹¤ê³  ì‘ë‹µí•  ê°€ëŠ¥ì„± ì¦ê°€
- 'ë‚˜ëŠ” ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œê¸°ë„ ì „ì— ìš°ë¦¬ëŠ” ì‹¸ì›€ì„ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.' <-> 'ì•„ë‚´ì™€ ì €ëŠ” ê²°í˜¼ ìƒí™œì—ì„œ ì—­í• ì´ ì–´ë– í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•˜ë‹¤.'
  -> ì‹¸ì›€ì´ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í• ìˆ˜ë¡ ê²°í˜¼ ì—­í• ì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•´ì§
- 'ë‚˜ëŠ” ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œê¸°ë„ ì „ì— ìš°ë¦¬ëŠ” ì‹¸ì›€ì„ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.' <-> 'ìš°ë¦¬ëŠ” ì‚¶ì—ì„œ í–‰ë³µí•´ì§€ëŠ” ê²ƒì— ëŒ€í•´ ì•„ë‚´ì™€ ê°™ì€ ê²¬í•´ë¥¼ ê³µìœ í•œë‹¤.'
  -> ì‹¸ì›€ì´ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•´ì§ˆìˆ˜ë¡ í–‰ë³µì— ëŒ€í•œ ë¹„ìŠ·í•œ ê²¬í•´ë¥¼ ê°€ì§

# **3. ë§‰ëŒ€ ê·¸ë˜í”„**
"""

import pandas as pd
import matplotlib.pyplot as plt
from google.colab import files
import os
import glob

# divorce_revised_selected_upper.xlsx ì—…ë¡œë“œ
print(" 'divorce_revised_selected_upper.xlsx' íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded = files.upload() # ì—…ë¡œë“œ ì°½ì´ ëœ¸

# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel('/content/divorce_revised_selected_upper.xlsx')

# 'Class'ë¥¼ ì œì™¸í•œ ëª¨ë“  ë³€ìˆ˜(ì»¬ëŸ¼) ì‹ë³„
feature_cols = [col for col in df.columns if col != 'Class']

# 'Class' (ê²°í˜¼ ìƒíƒœ) ë³„ í‰ê·  ì‘ë‹µ ì ìˆ˜ ê³„ì‚°
# Class=0: ê¸°í˜¼ì (Married), Class=1: ì´í˜¼ì (Divorced)
avg_scores = df.groupby('Class')[feature_cols].mean()
avg_scores.columns = feature_cols

# ê° ë³€ìˆ˜(ì»¬ëŸ¼)ë³„ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„± ë° ê²°ê³¼ì°½ì— í‘œì‹œ
for col in feature_cols:
    # í•´ë‹¹ ë³€ìˆ˜ì˜ ê¸°í˜¼ìì™€ ì´í˜¼ì í‰ê·  ì ìˆ˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ
    data_to_plot = avg_scores[col]

    # Matplotlib Figure ë° Axes ìƒì„±
    fig, ax = plt.subplots(figsize=(7, 5), dpi=1000)

    class_labels = ['Married (Class=0)', 'Divorced (Class=1)']
    avg_values = data_to_plot.values

    # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±
    bars = ax.bar(class_labels, avg_values, color=['#c6dbef', '#08306b'])

    # ì œëª© ë° ì¶• ë¼ë²¨ ì„¤ì • (ëª¨ë‘ ì˜ì–´ë¡œ ì„¤ì •)
    ax.set_title(f'Average Response Score for Variable {col}', fontsize=14, fontweight='bold')
    ax.set_xlabel('Marital Status', fontsize=12)
    ax.set_ylabel('Average Score', fontsize=12)

    # yì¶• ì‹œì‘ì ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë¹„ìœ¨ì„ ëª…í™•íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.
    if max(avg_values) > 0:
      ax.set_ylim(0, max(avg_values) * 1.2)
    else:
      ax.set_ylim(0, 1)

    # ê° ë§‰ëŒ€ ìœ„ì— í‰ê·  ì‘ë‹µ ì ìˆ˜ ê°’ í‘œì‹œ
    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.2f}',
                ha='center', va='bottom', fontsize=11, fontweight='semibold')

    # ê·¸ë¦¬ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
    ax.grid(axis='y', linestyle='--', alpha=0.7)

    # ê·¸ë˜í”„ ìš”ì†Œê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ ì¡°ì •
    plt.tight_layout()
    plt.figure(dpi=1000)
    plt.show()

"""# **4. ë°”ì´ì˜¬ë¦° í”Œë**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import numpy as np

# í°íŠ¸ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False

# ë³€ìˆ˜ ìš”ì•½ ì •ì˜
QUESTION_MAP = {
    'Atr8': 'Enjoy Holiday', 'Atr9': 'Enjoy Travel', 'Atr11': 'Long-term Harmony',
    'Atr12': 'Similar Values', 'Atr14': 'Similar Goals', 'Atr15': 'Dream Harmony',
    'Atr16': 'Love Definition', 'Atr17': 'Happiness View', 'Atr18': 'Marriage Views',
    'Atr19': 'Role Similarity', 'Atr20': 'Trust Values', 'Atr25': 'Know Inner World',
    'Atr26': 'Know Concerns', 'Atr27': 'Know Stressors', 'Atr28': 'Know Hopes',
    'Atr30': 'Know Social', 'Atr36': 'No Humiliation', 'Atr37': 'Calm Argument',
    'Atr39': 'Predictable Fight', 'Atr40': 'Fight Awareness', 'Atr41': 'Maintain Calm',
}

all_features = list(QUESTION_MAP.keys())

# íŒŒì¼ ì—…ë¡œë“œ
print(" 'divorce_revised_selected_upper.xlsx' íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded = files.upload()

# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel('divorce_revised_selected_upper.xlsx')

print("\nVisualization: Generating 21 individual Violin Plots for score distribution by Marital Status.")

valid_features = [col for col in all_features if col in df.columns]
plot_df = df[valid_features + ['Class']].copy()

plot_df['Class'] = plot_df['Class'].astype('category').replace(
    {0: 'Married (0)', 1: 'Divorced (1)'}
)

# ê¸€ì”¨ í¬ê¸° í™•ëŒ€
title_font = 22
label_font = 16
tick_font = 14
mean_font = 14

for col in valid_features:
    fig, ax = plt.subplots(figsize=(8, 6), dpi=1000)

    title_label = QUESTION_MAP.get(col, col)

    sns.violinplot(
        x='Class',
        y=col,
        data=plot_df,
        ax=ax,
        palette={'Married (0)': '#c6dbef', 'Divorced (1)': '#08306b'},
        inner='quartile',
        linewidth=1.5
    )

    # í‰ê·  ì ìˆ˜
    mean_scores = plot_df.groupby('Class')[col].mean()
    ax.scatter([0, 1], [mean_scores['Married (0)'], mean_scores['Divorced (1)']],
               color='black', s=120, zorder=3)

    # ì œëª©Â·ì¶•ãƒ©ë²¨Â·ëˆˆê¸ˆ ê¸€ì”¨ í¬ê¸° UP
    ax.set_title(f'Violin Plot: {title_label} ({col})',
                 fontsize=title_font, fontweight='bold')
    ax.set_xlabel('Marital Status (Class)', fontsize=label_font)
    ax.set_ylabel('Response Score', fontsize=label_font)

    ax.tick_params(axis='both', labelsize=tick_font)

    # Yì¶• ë²”ìœ„
    ax.set_ylim(-0.5, 4.5)
    ax.grid(axis='y', linestyle='--', alpha=0.6)

    # í‰ê·  í…ìŠ¤íŠ¸
    ax.text(0, mean_scores['Married (0)'] - 0.25,
            f'Avg: {mean_scores["Married (0)"]:.2f}',
            ha='center', fontsize=mean_font, fontweight='bold')

    ax.text(1, mean_scores['Divorced (1)'] - 0.25,
            f'Avg: {mean_scores["Divorced (1)"]:.2f}',
            ha='center', fontsize=mean_font, fontweight='bold')

    plt.tight_layout()
    plt.show()

"""# **ì „ì²´ ë¶„í¬ ë¶„ì„ ê°œìš”**
1. ê·¹ë‹¨ì ì¸ ì–‘ê·¹í™”: ì‘ë‹µ ì ìˆ˜ê°€ ëŒ€ì²´ë¡œ 0ì  ë˜ëŠ” 4ì  ê·¼ì²˜ì— ì••ë„ì ìœ¼ë¡œ ì§‘ì¤‘ë¨.
2. ëª…í™•í•œ ë¶„ë¦¬: ê¸°í˜¼ ê·¸ë£¹ê³¼ ì´í˜¼ ê·¸ë£¹ì˜ ë¶„í¬ê°€ ì™„ì „ ë¶„ë¦¬ë¨.
3. ì—­ë°©í–¥ íŒ¨í„´: ê¸°í˜¼ ê·¸ë£¹ì˜ í‰ê·  ì ìˆ˜ê°€ ë†’ì€ ë³€ìˆ˜ì´ë©´, ì´í˜¼ ê·¸ë£¹ì˜ í‰ê·  ì ìˆ˜ëŠ” ëŒ€ì²´ë¡œ ë‚®ìŒ.

# **íŒ¨í„´ 1: ê¸°í˜¼ ê·¸ë£¹ì´ ë†’ì€ ì ìˆ˜ë¥¼ ë³´ì´ëŠ” í•­ëª© (ê¸ì •ì  ê´€ê³„ íŠ¹ì„±)**
1. ê°ˆë“± ì¸ì‹(40) -> ê¸°í˜¼ í‰ê·  3.79, ì´í˜¼ í‰ê·  0.43
2. êµ´ìš• ì£¼ì§€ ì•ŠìŒ(36) -> ê¸°í˜¼ í‰ê·  3.63, ì´í˜¼ í‰ê·  0.45
3. ì¹¨ì°©ì„± ìœ ì§€(41) -> ê¸°í˜¼ í‰ê·  3.53, ì´í˜¼ í‰ê·  0.46

# **íŒ¨í„´ 2: í˜¼ ê·¸ë£¹ì´ ë†’ì€ ì ìˆ˜ë¥¼ ë³´ì´ëŠ” í•­ëª© (ê¸ì •ì  ê´€ê³„ íŠ¹ì„±)**
1. ì—­í•  ìœ ì‚¬ì„±(19) -> ê¸°í˜¼ í‰ê·  0.14, ì´í˜¼ í‰ê·  3.18
2. ì¥ê¸° ì¡°í™”(11) -> ê¸°í˜¼ í‰ê·  0.2, ì´í˜¼ í‰ê·  3.18
3. ì‹ ë¢° ê°€ì¹˜(20) -> ê¸°í˜¼ í‰ê·  0.14, ì´í˜¼ í‰ê·  2.95

#**ê²°ë¡ **
- ê°ˆë“±ì„ ê²ªì„ ë•Œì˜ íƒœë„ê°€ ê²°í˜¼ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ ê°€ì¥ ê°•ë ¥í•œ ë¶„ë¦¬ë ¥ì„ ë³´ì—¬ì£¼ëŠ” ë…¼ë¦¬ì  ê·¼ê±°.
- ìƒê°, ê°€ì¹˜ê´€ì˜ ì¡°í™”ê°€ ì•„ë¬´ë¦¬ ë†’ì„ì§€ë¼ë„ ê°ˆë“±ì„ ê²ªëŠ” íƒœë„ê°€ ë¬´ë„ˆì§€ë©´ ì´í˜¼ì— ì´ë¥´ê¸° ì‰¬ì›€.

# **5. ëª¨ìì´í¬ í”Œë**
"""

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.graphics.mosaicplot import mosaic
import matplotlib.font_manager as fm
import os
from google.colab import files

# divorce_revised_selected_upper.xlsx ì—…ë¡œë“œ
print(" 'divorce_revised_selected_upper.xlsx' íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
uploaded = files.upload() # ì—…ë¡œë“œ ì°½ì´ ëœ¸

# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel('divorce_revised_selected_upper.xlsx')

# ëª¨ë“  ì»¬ëŸ¼ì„ ë²”ì£¼í˜•(Category)ìœ¼ë¡œ ë³€í™˜
for col in df.columns:
    df[col] = df[col].astype('category')

# 'Class' ì»¬ëŸ¼ì„ ì œì™¸í•œ ì†ì„± ëª©ë¡ ì •ì˜
attribute_cols = df.columns.drop('Class').tolist()

#  21ê°œ ëª¨ìì´í¬ í”Œë ìƒì„± ë° ì¶œë ¥

for col in attribute_cols:
    # í”Œëë§ˆë‹¤ ìƒˆë¡œìš´ Figure ìƒì„±
    fig, ax = plt.subplots(figsize=(8, 6))

    # ëª¨ìì´í¬ í”Œë ìƒì„±
    mosaic(df,
           index=['Class', col],
           ax=ax,
           title='',
           labelizer=lambda k: '',
           # Matplotlib ê²½ê³  ì œê±°ë¥¼ ìœ„í•œ ìµœì‹  ì»¬ëŸ¬ë§µ ë¬¸ë²• ì ìš©
           properties=lambda k: {'color': plt.colormaps['Blues'](int(k[1])/4)}
          )

    # ì¶• ë ˆì´ë¸” ì„¤ì • (ì˜ë¬¸ ìœ ì§€)
    ax.set_xlabel('Class (0: Married, 1: Divorced)')
    ax.set_ylabel(f'{col} Value (0 to 4)')


    plt.show()

"""# **í•µì‹¬ ì°¨ë³„ ìš”ì†Œ: 'ê°ˆë“± ë° ë…¼ìŸ ì‹œì˜ íƒœë„'**
- í‰ê·  ì°¨ì´(ê¸°í˜¼ì í‰ê·  - ì´í˜¼ì í‰ê· )ê°€ ê°€ì¥ í¬ê²Œ ë‚˜íƒ€ë‚œ ìƒìœ„ 5ê°œ ë³€ìˆ˜ëŠ” ëª¨ë‘ ë°°ìš°ìì™€ì˜ ê°ˆë“± ìƒí™©ì—ì„œ ê°ì •ì„ ì¡°ì ˆí•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŠ¥ë ¥ê³¼ ê´€ë ¨ë˜ì–´ ìˆìŒ
- ì´ ë³€ìˆ˜ë“¤ì—ì„œ ê¸°í˜¼ì ê·¸ë£¹ì˜ í‰ê·  ì ìˆ˜(4ì  ë§Œì  ê¸°ì¤€)ê°€ ì••ë„ì ìœ¼ë¡œ ë†’ìŒ
- ì´ëŠ” ê¸°í˜¼ìë“¤ì´ ê°ˆë“± ìƒí™©ì„ ë§¤ìš° ê¸ì •ì ì´ê³  ê±´ì„¤ì ìœ¼ë¡œ ê´€ë¦¬í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸

# **í‰ê·  ì°¨ì´ê°€ ê°€ì¥ í¬ê²Œ ë‚˜íƒ€ë‚œ ìƒìœ„ 5ê°œ ë³€ìˆ˜(ê¸°í˜¼ìê°€ ìœ„)**
1. ë‚˜ëŠ” ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì•Œê¸°ë„ ì „ì— ìš°ë¦¬ëŠ” ì‹¸ì›€ì„ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.(40)
2. ë‚˜ëŠ” ìš°ë¦¬ê°€ ë…¼ìŸí•  ë•Œ êµ´ìš•ê°ì„ ì¤„ ìˆ˜ ì—†ë‹¤.(36)
3. ë‚´ê°€ ì•„ë‚´ì™€ ë¬´ì–¸ê°€ì— ëŒ€í•´ ì´ì•¼ê¸°í•  ë•Œ, ë‚´ ì°¨ë¶„í•¨ì€ ìœ ì§€ëœë‹¤.(41)
4. ì‹¸ì›€ì´ ê°‘ìê¸° ì¼ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤.(39)
5. ë‚´ ì•„ë‚´ì™€ì˜ ë…¼ìŸì€ ì°¨ë¶„í•˜ë‹¤. (37)

# **í‰ê·  ì°¨ì´ê°€ ê°€ì¥ í¬ê²Œ ë‚˜íƒ€ë‚œ ìƒìœ„ 5ê°œ ë³€ìˆ˜(ì´í˜¼ìê°€ ìœ„)**
1. ê²°í˜¼ ìƒí™œì—ì„œ ì—­í• ì— ëŒ€í•œ ìƒê°ì´ ë¹„ìŠ·í•˜ë‹¤.(19)
2. ì–¸ì  ê°€ ë’¤ëŒì•„ë³¼ ë•Œ ì„œë¡œ ì¡°í™”ë¥¼ ì´ë£¨ê³  ìˆë‹¤ê³  ìƒê°í•œë‹¤.(11)
3. ì‚¶ì—ì„œ í–‰ë³µí•´ì§€ëŠ” ê²ƒì— ëŒ€í•´ ì•„ë‚´ì™€ ê°™ì€ ê²¬í•´ë¥¼ ê³µìœ í•œë‹¤.(17)
4. ì•„ë‚´ì˜ ë‚´ë©´ ì„¸ê³„ë¥¼ ì•Œê³  ìˆë‹¤.(25)
5. ì•„ë‚´ì˜ ì¹œêµ¬ë“¤ê³¼ ê·¸ë“¤ì˜ ì‚¬íšŒì  ê´€ê³„ë¥¼ ì•ˆë‹¤.(30)

# **XAI ê¸°ë²• ì ìš©**
- 11/12(ìˆ˜) ~

## 1. Decision Tree - ìœ ë¦¼
"""

# ============================================
# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# ============================================
!pip install openpyxl
# ============================================
# 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
# ============================================
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
# ============================================
# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
#    (ì—­ì½”ë”©/ì‚­ì œê¹Œì§€ ëë‚œ ìµœì¢… íŒŒì¼ ì‚¬ìš©)
# ============================================
df = pd.read_excel("/content/divorce_revised_selected.xlsx")

y = df["Class"]
X = df.drop(columns=["Class"])

print("X shape:", X.shape)
# ============================================
# 3. ëœë¤í¬ë ˆìŠ¤íŠ¸ë¡œ ìƒìœ„ 21ê°œ ë³€ìˆ˜ ì„ íƒ
# ============================================
rf = RandomForestClassifier(n_estimators=128, random_state=42)
rf.fit(X, y)

importances = pd.Series(rf.feature_importances_, index=X.columns)

top_n = 21
top_features = importances.sort_values(ascending=False).head(top_n).index.tolist()

# ìƒìœ„ 21ê°œ ë³€ìˆ˜ë§Œ ì‚¬ìš©
X_top = X[top_features]

# ============================================
# 4. ìƒìœ„ 21ê°œ ë³€ìˆ˜ë¡œ Decision Tree í•™ìŠµ
#    (ì‹œê°í™”ë¥¼ ìœ„í•´ ë„ˆë¬´ ë³µì¡í•˜ì§€ ì•Šê²Œ max_depth ì œí•œ)
# ============================================
dt = DecisionTreeClassifier(
    criterion="gini",
    max_depth=4,         # íŠ¸ë¦¬ ê¹Šì´ (í•„ìš”í•˜ë©´ 3, 5 ë“±ìœ¼ë¡œ ì¡°ì ˆ)
    min_samples_leaf=5,  # ë„ˆë¬´ ê°€ì§€ê°€ ì˜ê²Œ ìª¼ê°œì§€ì§€ ì•Šë„ë¡
    random_state=42
)
dt.fit(X_top, y)

print("\nâœ… Decision Tree í•™ìŠµ ì™„ë£Œ")

# ============================================
# 5. ê²°ì •íŠ¸ë¦¬ ì‹œê°í™”
# ============================================
plt.figure(figsize=(24, 12))  # ìŠ¬ë¼ì´ë“œ/ë³´ê³ ì„œìš©ì´ë©´ í¬ê²Œ
plot_tree(
    dt,
    feature_names=top_features,      # ìƒìœ„ 21ê°œ ë³€ìˆ˜ ì´ë¦„
    class_names=["Not divorce", "Divorce"],  # Class 0, 1 ì´ë¦„
    filled=True,                    # ë…¸ë“œ ìƒ‰ìœ¼ë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ í‘œì‹œ
    rounded=True,                   # ë‘¥ê·¼ ë°•ìŠ¤
    fontsize=9
)
plt.title("Decision Tree using Top 21 Features", fontsize=16)
plt.show()

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# ë…¸ë“œê°€ ë” í¬ê²Œ ë³´ì´ë„ë¡ ì „ì²´ í°íŠ¸/ë ˆì´ì•„ì›ƒ ì¡°ì •
plt.rcParams['font.size'] = 18          # ì „ì²´ í°íŠ¸ í¬ê²Œ
plt.rcParams['axes.titlesize'] = 26
plt.rcParams['figure.autolayout'] = True

# ë°•ìŠ¤ ë‚´ë¶€ ì—¬ë°± ì»¤ì§€ë„ë¡
plt.rcParams['patch.linewidth'] = 2
plt.rcParams['patch.edgecolor'] = 'black'

# â–¶â–¶ ì—¬ê¸°ì„œ figsizeë¥¼ ë§¤ìš° í¬ê²Œ ì„¤ì •í•˜ì—¬ ë…¸ë“œë„ ê°•ì œë¡œ ì»¤ì§
plt.figure(figsize=(42, 32), dpi=800)

plot_tree(
    dt,
    feature_names=top_features,
    class_names=["Not divorce", "Divorce"],
    filled=True,
    rounded=True,
    proportion=False,     # ğŸ”¥ ë…¸ë“œë¥¼ ë¹„ìœ¨ ê¸°ì¤€ì´ ì•„ë‹Œ ì ˆëŒ€ í¬ê¸°ë¡œ í‘œí˜„
    fontsize=18           # ğŸ”¥ ë…¸ë“œ ë‚´ë¶€ ê¸€ì”¨ í¬ê²Œ â†’ ë°•ìŠ¤ë„ ì»¤ì§
)

plt.title("Decision Tree (Top 21 Features)", fontsize=28, fontweight="bold")
plt.show()

"""### ê²°ê³¼ í•´ì„
--------------------------------
1. ê²°ì • íŠ¸ë¦¬ ì „ì²´ í•´ì„
- ìƒìœ„ 21ê°œ ë³€ìˆ˜ ì¤‘ì—ì„œ
Atr18 â†’ Atr20 ìˆœìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•œ ë¶„ê¸° ê¸°ì¤€ì„ ì°¾ì•„ëƒ„
- ì´ ë‘ ë¬¸í•­ì´ ì´í˜¼ ì—¬ë¶€ë¥¼ ê°€ì¥ ì˜ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì´ë¼ê³  ëª¨ë¸ì´ íŒë‹¨

2. ë£¨íŠ¸ ë…¸ë“œ (ë§¨ ìœ„)
- ë°ì´í„° ì „ì²´(170ëª…) ì¤‘ ì´í˜¼ ì•„ë‹˜(0) 86ëª…, ì´í˜¼(1) 84ëª…ìœ¼ë¡œ ê±°ì˜ ë°˜ë°˜ì„  -> gini=0.5 ëŠ” í˜¼í•©ë„ê°€ ë†’ë‹¤ëŠ” ëœ»

=> Atr18ì˜ ì‘ë‹µì´ ë‚®ì€ê°€(â‰¤1.5) vs ë†’ì€ê°€(>1.5)ì— ë”°ë¼ ì´í˜¼ ì—¬ë¶€ê°€ í¬ê²Œ ê°ˆë¦¼

3. ì™¼ìª½ ê°€ì§€ (Atr18 â‰¤ 1.5ì¸ ì‚¬ëŒë“¤)
- Atr18 ì ìˆ˜ê°€ ë‚®ì€ ì‚¬ëŒ 89ëª… ì¤‘
86ëª…ì€ ì´í˜¼ì´ ì•„ë‹˜, 3ëª…ë§Œ ì´í˜¼.ê±°ì˜ ì „ë¶€ â€œì´í˜¼ ì•„ë‹˜â€ìœ¼ë¡œ íŒë‹¨ë¨.
- ì´ ê·¸ë£¹ ì•ˆì—ì„œë„ Atr20 ê°’ì´ 0.5 ì´í•˜ì¸ ê²½ìš° ëŒ€ë¶€ë¶„ ê²°í˜¼ ìœ ì§€ ìª½ìœ¼ë¡œ ë¶„ë¥˜ë¨.

=> Atr18ê³¼ Atr20ì´ ë‘˜ ë‹¤ ë‚®ì€ ì‚¬ëŒì€ ê±°ì˜ í™•ì‹¤í•˜ê²Œ ê²°í˜¼ ìœ ì§€.

4. ì˜¤ë¥¸ìª½ ê°€ì§€ (Atr18 > 1.5ì¸ ì‚¬ëŒë“¤)

- Atr18ì´ ë†’ì€ ì‚¬ëŒì€ ëª¨ë‘(81ëª…) ì´í˜¼.
- gini=0.0ì€ ì™„ë²½íˆ í•œìª½ìœ¼ë¡œë§Œ ë¶„ë¥˜ëœë‹¤ëŠ” ëœ»ì´ì•¼.
- Atr18 ë¬¸í•­ì—ì„œ ì ìˆ˜ê°€ 2 ì´ìƒì´ë©´ ì´í˜¼ í™•ë¥  100%.

=> Atr18ì´ ëª¨ë¸ì—ì„œ â€˜ê²°ì •ì  ì´í˜¼ ì‹ í˜¸â€™ ì—­í• ì„ í•¨

----------------------------

| ë¶„ê¸° ìˆœì„œ | ì¡°ê±´                            | ê²°ê³¼             | í•´ì„                   |
| ----- | ----------------------------- | -------------- | -------------------- |
| â‘      | `Atr18 > 1.5`                 | â†’ Divorce      | ì´ ë¬¸í•­ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ë¬´ì¡°ê±´ ì´í˜¼  |
| â‘¡     | `Atr18 â‰¤ 1.5`                 | â†’ Atr20 í™•ì¸     | ì´ ë¬¸í•­ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ëŒ€ë¶€ë¶„ ì•ˆì •ì  |
| â‘¢     | `Atr18 â‰¤ 1.5` & `Atr20 â‰¤ 0.5` | â†’ Not divorce  | ì™„ì „íˆ ì•ˆì •ì  ê´€ê³„           |
| â‘£     | `Atr18 â‰¤ 1.5` & `Atr20 > 0.5` | â†’ ì•½ê°„ í˜¼í•©(ì¡°ê¸ˆ ìœ„í—˜) | ì¼ë¶€ë§Œ ì´í˜¼, ëŒ€ë¶€ë¶„ ì•ˆì •       |



--------------

5. ê²°ë¡ 

- Atr18: ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì¤€
-> ì´ ë¬¸í•­ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ê±°ì˜ ì´í˜¼

- Atr20: ë³´ì¡° ê¸°ì¤€
-> Atr18ì´ ë‚®ì€ ì‚¬ëŒ ì¤‘ì—ì„œë„, Atr20 ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ì•½ê°„ ìœ„í—˜

# 2. SAHP summary plot - ìœ ë¦¼
- 11/17(ì›”)
"""

# ==========================================================
# Divorce ì„¤ë¬¸ ë°ì´í„°: ìƒìœ„ 21ê°œ ë¬¸í•­ì— ëŒ€í•œ SHAP summary plot
# ==========================================================

# 0. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ ì‹¤í–‰)
!pip install shap openpyxl

# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import shap

# ----------------------------------------------------------
# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ----------------------------------------------------------
# divorce_revised_selected.xlsx : ì—­ì½”ë”© ë° ë¶ˆí•„ìš” ë¬¸í•­ ì‚­ì œê°€ ëë‚œ ìµœì¢… ë°ì´í„°
df = pd.read_excel("/content/divorce_revised_selected.xlsx")

# Class : íƒ€ê¹ƒ(ì´í˜¼ ì—¬ë¶€), ë‚˜ë¨¸ì§€ Atr* : ì„¤ë¬¸ ë¬¸í•­ ì ìˆ˜
y = df["Class"]
X = df.drop(columns=["Class"])

print("âœ… ë°ì´í„° í¬ê¸°:", X.shape)  # (ìƒ˜í”Œ ìˆ˜, ë³€ìˆ˜ ìˆ˜)
print("âœ… ì˜ˆì‹œ ì»¬ëŸ¼:", list(X.columns[:10]))

# ----------------------------------------------------------
# 3. ì „ì²´ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ RandomForest í•™ìŠµ
#    â†’ MDI(ë¶ˆìˆœë„ ê°ì†ŒëŸ‰) ê¸°ì¤€ ìƒìœ„ 21ê°œ ë¬¸í•­ ì„ íƒ
# ----------------------------------------------------------
rf_all = RandomForestClassifier(
    n_estimators=128,
    random_state=42
)
rf_all.fit(X, y)

# feature_importances_ : MDI ë°©ì‹ ë³€ìˆ˜ ì¤‘ìš”ë„
importances = pd.Series(rf_all.feature_importances_, index=X.columns)

top_n = 21
top_features = importances.sort_values(ascending=False).head(top_n).index.tolist()

print(f"\nğŸ… MDI ê¸°ì¤€ ìƒìœ„ {top_n}ê°œ ë¬¸í•­:")
for i, f in enumerate(top_features, 1):
    print(f"{i:2d}. {f}")

# ìƒìœ„ 21ê°œ ë¬¸í•­ë§Œ ë‚¨ê¸´ ì…ë ¥ ë°ì´í„°
X_top = X[top_features]

# ----------------------------------------------------------
# 4. ìƒìœ„ 21ê°œ ë¬¸í•­ìœ¼ë¡œ ë‹¤ì‹œ RandomForest í•™ìŠµ
#    (ì´ ëª¨ë¸ì„ ê¸°ì¤€ìœ¼ë¡œ SHAP ê³„ì‚°)
# ----------------------------------------------------------
rf_top = RandomForestClassifier(
    n_estimators=128,
    random_state=42
)
rf_top.fit(X_top, y)
print("\nâœ… ìƒìœ„ 21ê°œ ë¬¸í•­ìœ¼ë¡œ RandomForest ì¬í•™ìŠµ ì™„ë£Œ")

# ----------------------------------------------------------
# 5. SHAP ê°’ ê³„ì‚° (í´ë˜ìŠ¤ 1 ê¸°ì¤€)
# ----------------------------------------------------------
explainer = shap.TreeExplainer(rf_top)
shap_values = explainer.shap_values(X_top)

print("shap_values íƒ€ì…:", type(shap_values))

# shap ë²„ì „ì— ë”°ë¼ ì¶œë ¥ í˜•íƒœê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¶„ê¸° ì²˜ë¦¬
if isinstance(shap_values, list):
    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°: [class0, class1, ...] í˜•íƒœ
    print("í´ë˜ìŠ¤ ìˆ˜:", len(shap_values))
    # ì´ì§„ë¶„ë¥˜ì´ë¯€ë¡œ ë³´í†µ 'ì´í˜¼'ì— í•´ë‹¹í•˜ëŠ” class 1 ì‚¬ìš©
    shap_values_to_plot = shap_values[1]
else:
    # ë°°ì—´ì¸ ê²½ìš°: (ìƒ˜í”Œ ìˆ˜, íŠ¹ì„± ìˆ˜) ë˜ëŠ” (ìƒ˜í”Œ ìˆ˜, íŠ¹ì„± ìˆ˜, í´ë˜ìŠ¤ ìˆ˜)
    print("shap_values shape:", shap_values.shape)
    if shap_values.ndim == 3:
        # (n_samples, n_features, n_classes) í˜•íƒœë¼ë©´
        n_classes = shap_values.shape[2]
        class_idx = 1 if n_classes > 1 else 0
        shap_values_to_plot = shap_values[:, :, class_idx]
        print("â†’ í´ë˜ìŠ¤", class_idx, "ê¸°ì¤€ SHAP ì‚¬ìš©, shape:", shap_values_to_plot.shape)
    else:
        shap_values_to_plot = shap_values

# ----------------------------------------------------------
# 6. SHAP Summary Plot (Top 21 features)
# ----------------------------------------------------------
plt.figure(figsize=(8, 10), dpi=1000)
shap.summary_plot(
    shap_values_to_plot,  # ê° ìƒ˜í”ŒÃ—íŠ¹ì„±ì˜ SHAP ê°’
    X_top,                # ìƒìœ„ 21ê°œ ë¬¸í•­ë§Œ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
    plot_type="dot",
    max_display=top_n,
    show=False
)

plt.title(f"SHAP Summary Plot (Top {top_n} Features)", fontsize=14)
plt.tight_layout()
plt.show()

"""## ê²°ê³¼ í•´ì„

1. yì¶•: ìƒìœ„ 21ê°œ ë¬¸í•­
- ìœ„ì— ìˆì„ìˆ˜ë¡ ì „ì²´ì ìœ¼ë¡œ ë” ì¤‘ìš”í•œ ë¬¸í•­
2. xì¶•: SHAP value
- 0ë³´ë‹¤ ì˜¤ë¥¸ìª½(+): ê·¸ ë¬¸í•­ì˜ ì‘ë‹µ ë•Œë¬¸ì— ì´í˜¼(class=1) ì˜ˆì¸¡ í™•ë¥ ì´ ì¦ê°€í•œ ë°©í–¥
- 0ë³´ë‹¤ ì™¼ìª½(-): ê·¸ ë¬¸í•­ì˜ ì‘ë‹µ ë•Œë¬¸ì— ì´í˜¼ì´ ì•„ë‹ (class=0) í™•ë¥ ì´ ì¦ê°€í•œ ë°©í–¥
3. ìƒ‰ê¹”: í•´ë‹¹ ë¬¸í•­ì˜ ì‹¤ì œ ì‘ë‹µ ê°’
- íŒŒë‘(Low): ì ìˆ˜ê°€ ë‚®ì€ ì‘ë‹µ
- ë¹¨ê°•(High): ì ìˆ˜ê°€ ë†’ì€ ì‘ë‹µ

4. ì£¼ìš” ë³€ìˆ˜ í•´ì„
- Atr40ì—ì„œ í•‘í¬ ì ë“¤ì´ ì™¼ìª½(â€“)ìœ¼ë¡œ ëª°ë ¤ ìˆìœ¼ë©´
â†’ â€œAtr40 ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡, ì´í˜¼ì´ ì•„ë‹ ìª½ìœ¼ë¡œ ì˜ˆì¸¡ì´ ê°„ë‹¤â€

- Atr18ì—ì„œ í•‘í¬ ì ë“¤ì´ ì˜¤ë¥¸ìª½(+)ì´ë©´
â†’ â€œAtr18 ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡, ì´í˜¼ ì˜ˆì¸¡ì´ ê°•í™”ëœë‹¤â€

1ìœ„: Atr40
- ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ì´í˜¼ í™•ë¥ ì´ í¬ê²Œ ì¦ê°€í•˜ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜

2ìœ„: Atr18
- ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´í˜¼ í™•ë¥ ì„ ê¾¸ì¤€íˆ ì¦ê°€ì‹œí‚´
- ì „ì²´ì ìœ¼ë¡œ ì ë“¤ì´ ê· ì¼í•˜ê²Œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë¶„í¬í•˜ì—¬ 'ê³ ì ì¼ìˆ˜ë¡ ìœ„í—˜ ì¦ê°€' íŒ¨í„´ì´ í™•ì‹¤í•¨

3ìœ„: Atr17
- íŠ¹ì • ë²”ìœ„ ì´ìƒì—ì„œëŠ” ì ìˆ˜ê°€ ë†’ì•„ì§€ë©´ ì´í˜¼ ìœ„í—˜ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ì§€ë§Œ, ì ìˆ˜ê°€ ë‚®ì„ ë•ŒëŠ” ê±°ì˜ ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŒ
- (ì„ê³„ì ì´ ìˆëŠ” ë¬¸í•­ì²˜ëŸ¼ ë³´ì„)

4ìœ„: Atr19
- ì‘ë‹µ ì ìˆ˜ê°€ ë†’ìœ¼ë©´ ì´í˜¼ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í¬ê²Œ ê¸°ì—¬í•˜ì§€ë§Œ, ë‚®ìœ¼ë©´ ì˜¤íˆë ¤ 'ì´í˜¼í•˜ì§€ ì•Šì€ ë°©í–¥'ìœ¼ë¡œ ê¸°ì—¬

5ìœ„: Atr20
- ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì´í˜¼ ìª½ìœ¼ë¡œ ì•½~ì¤‘ê°„ ì •ë„ ê¸°ì—¬

# 3. SAHP force plot - ìœ ë¦¼
- 11/17(ì›”)
"""

import shap
import numpy as np

# TreeExplainerì™€ SHAP ê°’ ê³„ì‚°
explainer = shap.TreeExplainer(rf_top)
shap_values = explainer.shap_values(X_top)

# âœ… í´ë˜ìŠ¤ 1(ì´í˜¼) ê¸°ì¤€ SHAP ê°’ë§Œ ì¶”ì¶œ
if isinstance(shap_values, list):
    # shap_values: [class0, class1] í˜•íƒœ
    shap_values_class1 = shap_values[1]
else:
    # shap_values: (n_samples, n_features) ë˜ëŠ” (n_samples, n_features, n_classes)
    if shap_values.ndim == 3:
        class_idx = 1 if shap_values.shape[2] > 1 else 0
        shap_values_class1 = shap_values[:, :, class_idx]
    else:
        shap_values_class1 = shap_values

print("shap_values_class1 shape:", shap_values_class1.shape)  # (ìƒ˜í”Œ ìˆ˜, 21)

# âœ… expected valueë„ í´ë˜ìŠ¤ 1 ê¸°ì¤€ìœ¼ë¡œ ì¶”ì¶œ
ev = explainer.expected_value
if isinstance(ev, (list, np.ndarray)):
    expected_value_class1 = ev[1] if len(ev) > 1 else ev[0]
else:
    expected_value_class1 = ev

print("expected_value_class1:", expected_value_class1)

# ëŒ€í‘œ ìƒ˜í”Œ 3ê°œ ê³ ë¥´ëŠ” ì½”ë“œ

import numpy as np

# 1ï¸âƒ£ ê° ìƒ˜í”Œì˜ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° (ì´í˜¼=1 í´ë˜ìŠ¤ ê¸°ì¤€)
probs = rf_top.predict_proba(X_top)[:, 1]

# 2ï¸âƒ£ ì˜ˆì¸¡ê°’ì´ ê°€ì¥ ë†’ì€ ì‚¬ëŒ, ë‚®ì€ ì‚¬ëŒ, ì¤‘ê°„ ì‚¬ëŒ ì¸ë±ìŠ¤ ì°¾ê¸°
idx_high = np.argmax(probs)       # ì´í˜¼ í™•ë¥  ê°€ì¥ ë†’ì€ ì‚¬ëŒ
idx_low = np.argmin(probs)        # ì´í˜¼ í™•ë¥  ê°€ì¥ ë‚®ì€ ì‚¬ëŒ
idx_mid = np.argsort(np.abs(probs - 0.5))[0]  # 0.5 ê·¼ì²˜ì¸ ì¤‘ê°„ ì‚¬ëŒ

print("ğŸ”º High case (ì´í˜¼ ìœ„í—˜ ë†’ìŒ): idx =", idx_high, "í™•ë¥  =", probs[idx_high])
print("ğŸ”¹ Low case (ì´í˜¼ ìœ„í—˜ ë‚®ìŒ): idx =", idx_low, "í™•ë¥  =", probs[idx_low])
print("âšª Mid case (ì¤‘ê°„): idx =", idx_mid, "í™•ë¥  =", probs[idx_mid])

"""idx = 1 (ì´í˜¼ í™•ë¥  1.0)
- ëŒ€ë¶€ë¶„ì˜ ì‘ë‹µì´ ì´í˜¼ í™•ë¥ ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ì‘ìš©í•¨
-> ì´í˜¼ ìœ„í—˜êµ° ëŒ€í‘œ ì‚¬ë¡€
"""

# idx = 1 (ì´í˜¼ í™•ë¥  1.0)

# ìë°”ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ SHAP í”Œë¡¯ ì´ˆê¸°í™” (Colab/ë…¸íŠ¸ë¶ìš©)
shap.initjs()

# ì˜ˆì‹œë¡œ ì²« ë²ˆì§¸ ìƒ˜í”Œ(idx = 0)ì„ ì„ íƒ
idx = 1   # ë‹¤ë¥¸ ìƒ˜í”Œì„ ë³´ê³  ì‹¶ìœ¼ë©´ 1, 2, ... ë¡œ ë°”ê¿”ì„œ ì‹¤í–‰

# force plot (JS ë²„ì „, ìƒí˜¸ì‘ìš© ê°€ëŠ¥)
shap.force_plot(
    expected_value_class1,          # base value (í‰ê·  logit ë˜ëŠ” ì˜ˆì¸¡ê°’)
    shap_values_class1[idx, :],     # í•´ë‹¹ ìƒ˜í”Œì˜ SHAP ê°’ (ê¸¸ì´ 21)
    X_top.iloc[idx, :],             # í•´ë‹¹ ìƒ˜í”Œì˜ íŠ¹ì„± ê°’
)

"""idx=1 ê°„ë‹¨í•œ ê²°ê³¼ í•´ì„

- ì´ ì‚¬ëŒì€ Atr9, 11, 17, 18, 19, 20 ê°™ì€ í•µì‹¬ ë¬¸í•­ì—ì„œ ì ìˆ˜ê°€ ê½¤ ë†’ë‹¤(3~4ì )
- ê·¸ë¦¬ê³  ì´ ë¬¸í•­ë“¤ì˜ SHAP í™”ì‚´í‘œê°€ ëª¨ë‘ ë¹¨ê°„ìƒ‰Â·ì˜¤ë¥¸ìª½ì´ê¸° ë•Œë¬¸ì—,
â†’ ëª¨ë¸ì€ â€œì´ ë¬¸í•­ì—ì„œ ì´ëŸ° ì‘ë‹µì„ í•œ ì‚¬ëŒì€ ì´í˜¼ì¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤â€ê³  í•™ìŠµí•œ ìƒíƒœ
- Atr40 = 0 ëŠ” íŒŒë€ìƒ‰ìœ¼ë¡œ ì•½ê°„ ì™¼ìª½ìœ¼ë¡œ ë°€ê³  ìˆì–´ì„œ,
â†’ ì´ ë¬¸í•­ì˜ ì‘ë‹µì€ ì˜¤íˆë ¤ ì´í˜¼ ê°€ëŠ¥ì„±ì„ ì¡°ê¸ˆ ì¤„ì´ëŠ” ë³´í˜¸ ìš”ì¸ìœ¼ë¡œ ì‘ìš©

idx = 84 (ì´í˜¼ í™•ë¥  0.0)
- ëª¨ë¸ì€ ì´ ì‚¬ëŒì˜ ì‘ë‹µì´ ê²°í˜¼ ìœ ì§€ ìª½ì— ì•ˆì •ì ìœ¼ë¡œ ê¸°ì—¬í•œë‹¤ê³  ë´„
-> ì•ˆì •ëœ ê´€ê³„ ëŒ€í‘œ ì‚¬ë¡€
"""

# idx = 84 (ì´í˜¼ í™•ë¥  0.0)

# ìë°”ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ SHAP í”Œë¡¯ ì´ˆê¸°í™” (Colab/ë…¸íŠ¸ë¶ìš©)
shap.initjs()

# ì˜ˆì‹œë¡œ ì²« ë²ˆì§¸ ìƒ˜í”Œ(idx = 0)ì„ ì„ íƒ
idx = 84

# force plot (JS ë²„ì „, ìƒí˜¸ì‘ìš© ê°€ëŠ¥)
shap.force_plot(
    expected_value_class1,          # base value (í‰ê·  logit ë˜ëŠ” ì˜ˆì¸¡ê°’)
    shap_values_class1[idx, :],     # í•´ë‹¹ ìƒ˜í”Œì˜ SHAP ê°’ (ê¸¸ì´ 21)
    X_top.iloc[idx, :],             # í•´ë‹¹ ìƒ˜í”Œì˜ íŠ¹ì„± ê°’
)

"""idx=84 ê°„ë‹¨í•œ ê²°ê³¼ í•´ì„

- ì´ ì‚¬ëŒì€ ì¤‘ìš” ë¬¸í•­ë“¤ì—ì„œ ì ìˆ˜ê°€ ë‚®ê±°ë‚˜(0~1ì ), íŠ¹ì • ë°©í–¥ì˜ ì‘ë‹µì„ ì„ íƒí–ˆê³ ,
- ì´ ì‘ë‹µë“¤ì´ ëª¨ë‘ ëª¨ë¸ ì…ì¥ì—ì„œ ì´í˜¼ ìœ„í—˜ì´ ë‚®ì€ íŒ¨í„´ìœ¼ë¡œ ì¸ì‹ë¨
- íŠ¹íˆ Atr18, 19, 20, 11, 9 ê°™ì€ ë¬¸í•­ë“¤ì€ high caseì—ì„œ â€œìœ„í—˜ ì‹ í˜¸â€ì˜€ëŠ”ë°
ì—¬ê¸°ì„œëŠ” ë°˜ëŒ€ ë°©í–¥ì˜ ì‘ë‹µ(0ì )ì— ê°€ê¹Œì›Œì„œ,
â†’ ì´í˜¼ ì˜ˆì¸¡ê°’ì„ ë§ì´ ê¹ì•„ë‚´ë¦¬ëŠ” íŒŒë€ ìš”ì¸ë“¤ë¡œ ì‘ìš©

idx = 4 (ì´í˜¼ í™•ë¥  0.66)
- ë¹¨ê°•ê³¼ íŒŒë‘ì´ ì„ì—¬ ìˆìŒ
- ê¸ì •, ë¶€ì • ë¬¸í•­ì´ ë™ì‹œì— ì‘ìš©í•´ ëª¨ë¸ì´ íŒë‹¨ì„ ë§ì„¤ì¸ ì˜ˆì‹œ
-> ê²½ê³„ì„ (ì¤‘ê°„) ì‚¬ë¡€
"""

# idx = 4 (ì´í˜¼ í™•ë¥  0.66)

# ìë°”ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ SHAP í”Œë¡¯ ì´ˆê¸°í™” (Colab/ë…¸íŠ¸ë¶ìš©)
shap.initjs()

# ì˜ˆì‹œë¡œ ì²« ë²ˆì§¸ ìƒ˜í”Œ(idx = 0)ì„ ì„ íƒ
idx = 4

# force plot (JS ë²„ì „, ìƒí˜¸ì‘ìš© ê°€ëŠ¥)
shap.force_plot(
    expected_value_class1,          # base value (í‰ê·  logit ë˜ëŠ” ì˜ˆì¸¡ê°’)
    shap_values_class1[idx, :],     # í•´ë‹¹ ìƒ˜í”Œì˜ SHAP ê°’ (ê¸¸ì´ 21)
    X_top.iloc[idx, :],             # í•´ë‹¹ ìƒ˜í”Œì˜ íŠ¹ì„± ê°’
)

"""idx = 4 ê°„ë‹¨í•œ ê²°ê³¼ í•´ì„

- idx=4 ì‚¬ëŒì€ ìœ„í—˜ ì‹ í˜¸ì™€ ë³´í˜¸ ì‹ í˜¸ê°€ ì„ì—¬ ìˆê¸° ë•Œë¬¸ì—
- í‰ê· ë³´ë‹¤ ì´í˜¼ ê°€ëŠ¥ì„±ì€ ë†’ì§€ë§Œ(0.66), high caseì²˜ëŸ¼ ê·¹ë‹¨ì ìœ¼ë¡œ ìœ„í—˜í•˜ì§€ëŠ” ì•Šì€ â€˜ê²½ê³„ì„  ì‚¬ë¡€â€™ì´ë‹¤.
- íŠ¹ì • ë¬¸í•­ì—ì„œëŠ” ë¬¸ì œë¥¼ ë³´ì´ì§€ë§Œ, ë‹¤ë¥¸ ë¬¸í•­ì—ì„œëŠ” ê´€ê³„ë¥¼ ì§€ì¼œì£¼ëŠ” ìš”ì†Œë„ ì¡´ì¬í•œë‹¤.
"""

import matplotlib.pyplot as plt
import shap

plt.rcParams['font.size'] = 16  # ì „ì²´ ê¸€ì”¨ëŠ” ì ë‹¹íˆ í¬ê²Œ

idx_list  = [1, 84, 4]
name_list = ["high", "low", "mid"]

for idx, name in zip(idx_list, name_list):
    # 1) ìƒˆ ê·¸ë¦¼ ìƒì„± (í¬ê²Œ, ê³ í•´ìƒë„)
    plt.figure(figsize=(18, 4), dpi=400)

    # 2) matplotlib ë²„ì „ force plot
    shap.plots.force(
        expected_value_class1,        # base value
        shap_values_class1[idx, :],   # SHAP ê°’
        X_top.iloc[idx, :],           # íŠ¹ì„± ê°’
        matplotlib=True,
        show=False
    )

    # 3) f(x) ë¼ë²¨ë§Œ ì°¾ì•„ì„œ ì§€ìš°ê¸° / ì¤„ì´ê¸°
    fig = plt.gcf()
    for ax in fig.axes:
        for txt in ax.texts:
            if "f(x)" in txt.get_text():
                # ë°©ë²• 1: ì•„ì˜ˆ ìˆ¨ê¸°ê¸°
                txt.set_visible(False)
                # ë°©ë²• 2(ìˆ¨ê¸°ê¸° ëŒ€ì‹  ì“°ê³  ì‹¶ìœ¼ë©´): txt.set_fontsize(10)

    plt.tight_layout()

    # 4) ì´ˆê³ í•´ìƒë„ ì €ì¥
    plt.savefig(f"force_plot_{name}_1200dpi.png",
                dpi=1200, bbox_inches="tight")
    plt.savefig(f"force_plot_{name}.svg",
                bbox_inches="tight")

    plt.show()
    plt.close()

"""## ê²°ê³¼ í•´ì„

1. force plotì´ë€?
-  í•œ ì‚¬ëŒ(í•œ ìƒ˜í”Œ)ì˜ ì˜ˆì¸¡ê°’ì´ 'ì „ì²´ í‰ê· (base value)'ì—ì„œ 'ìµœì¢… ì˜ˆì¸¡ê°’(output value)'ìœ¼ë¡œ ë³€í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì£¼ëŠ” ì›ì¸ ë¶„ì„ ê·¸ë˜í”„

2. ìƒ‰ì˜ ì˜ë¯¸
- ë¹¨ê°„ìƒ‰: ì´ ë¬¸í•­ ë•Œë¬¸ì— ì´í˜¼ ì˜ˆì¸¡ê°’ì´ ì˜¬ë¼ê°
- íŒŒë€ìƒ‰: ì´ ë¬¸í•­ ë•Œë¬¸ì— ì´í˜¼ ì˜ˆì¸¡ê°’ì´ ë‚´ë ¤ê°

3. ë‚´ìš©
- base value â‰ˆ 0.49
â†’ ì•„ë¬´ ì •ë³´ë„ ëª¨ë¥¼ ë•Œ, í‰ê· ì ìœ¼ë¡œ ì´í˜¼ì¼ í™•ë¥ 
- output value
â†’ ì´ ì‚¬ëŒì˜ ì‘ë‹µê¹Œì§€ ë°˜ì˜í–ˆì„ ë•Œ ì´í˜¼ì¼ í™•ë¥ 
- ë¹¨ê°„ ë¸”ë¡ (higher)
â†’ ì´ ë¬¸í•­ì˜ ì‘ë‹µì´ ì´í˜¼ ìª½(Class=1) ìœ¼ë¡œ ì˜ˆì¸¡ì„ ë°€ì–´ ì˜¬ë¦¬ëŠ” ìš”ì¸
- íŒŒë€ ë¸”ë¡ (lower)
â†’ ì´ ë¬¸í•­ì˜ ì‘ë‹µì´ ì´í˜¼ì´ ì•„ë‹ ìª½(Class=0) ìœ¼ë¡œ ì˜ˆì¸¡ì„ ëŒì–´ë‚´ë¦¬ëŠ” ìš”ì¸

ï¼ï¼ ì´ force plotì€ ê°œì¸ ë‹¨ìœ„ì˜ ì›ì¸ ë¶„ì„(local explanationn)ì„ í•´ì£¼ëŠ” ê·¸ë˜í”„

â†’ summary plotì€ ì „ì²´ì ì¸ ë³€ìˆ˜ ì˜í–¥ë ¥ì„ ë³´ì—¬ì¤Œ

â†’ force plotì€ í•œ ì‚¬ëŒì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë§Œë“  êµ¬ì²´ì  ì›ì¸ì„ ë³´ì—¬ì¤Œ

# 4. SHAP Waterfall Plot - ë¬¸ì˜ì‹ 
"""

from sklearn.cluster import KMeans
import numpy as np

representatives = {}

for cls in [0, 1]:
    X_cls = X_top[y == cls]

    # KMeans í´ëŸ¬ìŠ¤í„°ë§ (3ê°œ ê·¸ë£¹)
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(X_cls)

    centers = kmeans.cluster_centers_
    labels = kmeans.labels_

    rep_idx = []

    for i in range(3):
        cluster_points = X_cls[labels == i]
        cluster_idx = cluster_points.index

        # centroidì™€ ê°€ì¥ ê°€ê¹Œìš´ ìƒ˜í”Œ ì°¾ê¸°
        distances = np.linalg.norm(cluster_points.values - centers[i], axis=1)
        nearest_local = np.argmin(distances)

        rep_idx.append(int(cluster_idx[nearest_local]))

    representatives[cls] = rep_idx

print("\n í´ë˜ìŠ¤ë³„ ëŒ€í‘œ ìƒ˜í”Œ ì¸ë±ìŠ¤ (ì •ìˆ˜í˜•ìœ¼ë¡œ ì¶œë ¥):")
for cls in representatives:
    print(f"Class {cls}: {representatives[cls]}")

# ================================================================
# PCA + í´ë˜ìŠ¤ë³„ KMeans ì‹œê°í™” (ëŒ€í‘œ ìƒ˜í”Œì€ ë³„ í‘œì‹œ)
# ================================================================
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# ---- 1) PCA (2ì°¨ì› ì¶•ì†Œ) ----
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_top)

# PCA ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„í™” (í´ë˜ìŠ¤ / ëŒ€í‘œ ì—¬ë¶€ ì‹œê°í™” ìœ„í•´)
pca_df = pd.DataFrame({
    "PC1": X_pca[:, 0],
    "PC2": X_pca[:, 1],
    "Class": y.values
})

# ---- 2) í´ë˜ìŠ¤ë³„ ì‹œê°í™” ----
for cls in [0, 1]:
    X_cls_idx = pca_df[pca_df["Class"] == cls].index

    # í´ë˜ìŠ¤ ë°ì´í„°ë§Œ ì„ íƒ
    X_cls_pca = X_pca[X_cls_idx]

    # KMeans 3í´ëŸ¬ìŠ¤í„°
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(X_top.loc[X_cls_idx])
    labels_cls = kmeans.labels_

    # ---- ì‹œê°í™” ----
    plt.figure(figsize=(7, 6), dpi = 1000)
    scatter = plt.scatter(
        X_cls_pca[:, 0],
        X_cls_pca[:, 1],
        c=labels_cls,
        cmap='viridis',
        s=60,
        alpha=0.85
    )

    # ëŒ€í‘œ ìƒ˜í”Œ í‘œì‹œ
    reps = representatives[cls]   # ëŒ€í‘œ ìƒ˜í”Œ ì¸ë±ìŠ¤ 3ê°œ
    for ridx in reps:
        plt.scatter(
            pca_df.loc[ridx, "PC1"],
            pca_df.loc[ridx, "PC2"],
            s=200,
            marker='*',
            color='red',
            linewidths=1.3,
            label="Representative Sample" if ridx == reps[0] else ""
        )

    plt.title(f"Class {cls} - KMeans Clustering (PCA 2D)", fontsize=15)
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.colorbar(scatter, label="Cluster Label")

    # ë²”ë¡€ í•œ ë²ˆë§Œ í‘œì‹œ
    plt.legend()
    plt.grid(alpha=0.3)
    plt.show()

import matplotlib
matplotlib.rcParams['axes.unicode_minus'] = False

for cls in representatives:
    print(f"\n==============================")
    print(f"      CLASS {cls} ëŒ€í‘œ ìƒ˜í”Œ")
    print(f"==============================")

    for idx in representatives[cls]:
        print(f"\nğŸ“Œ Waterfall Plot â€” Sample Index {idx}")

        expl = shap.Explanation(
            values = shap_values_to_plot[idx],
            base_values = explainer.expected_value[1],  # í´ë˜ìŠ¤ 1 ê¸°ì¤€
            data = X_top.loc[idx].values,
            feature_names = X_top.columns
        )

        shap.plots.waterfall(expl, max_display=21)
        plt.figure(dpi=1200)

"""# 5. SHAP decision plot - ìœ ë¦¼"""

import numpy as np

# ì´í˜¼(í´ë˜ìŠ¤ 1) í™•ë¥ 
probs = rf_top.predict_proba(X_top)[:, 1]

idx_high = np.argmax(probs)                          # ì´í˜¼ í™•ë¥  ê°€ì¥ ë†’ì€ ì‚¬ëŒ
idx_low  = np.argmin(probs)                          # ì´í˜¼ í™•ë¥  ê°€ì¥ ë‚®ì€ ì‚¬ëŒ
idx_mid  = np.argsort(np.abs(probs - 0.5))[0]        # 0.5ì— ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ëŒ

print("ğŸ”º High case :", idx_high, "prob =", probs[idx_high])
print("ğŸ”¹ Low case  :", idx_low,  "prob =", probs[idx_low])
print("âšª Mid case  :", idx_mid,  "prob =", probs[idx_mid])

sample_idx = [idx_high, idx_low, idx_mid]

# explainer.expected_valueë„ ì´ì§„ë¶„ë¥˜ë¼ë©´ [class0, class1] í˜•íƒœì¼ ìˆ˜ ìˆìŒ
ev = explainer.expected_value
if isinstance(ev, (list, np.ndarray)):
    expected_value_class1 = ev[1] if len(ev) > 1 else ev[0]
else:
    expected_value_class1 = ev

print("expected_value_class1:", expected_value_class1)

import matplotlib.pyplot as plt
import shap
import numpy as np

# í°íŠ¸ í¬ê¸° ì „ì²´ í™•ëŒ€ ------------------------
plt.rcParams['font.size'] = 18          # ê¸°ë³¸ ê¸€ì”¨ í¬ê¸°
plt.rcParams['axes.titlesize'] = 20     # ì œëª© í¬ê¸°
plt.rcParams['axes.labelsize'] = 20     # ì¶• ë¼ë²¨ í¬ê¸°
plt.rcParams['xtick.labelsize'] = 20    # Xì¶• tick
plt.rcParams['ytick.labelsize'] = 20    # Yì¶• tick
plt.rcParams['legend.fontsize'] = 15    # ë²”ë¡€ ê¸€ì”¨ í¬ê¸°

# 1) ì´í˜¼ í™•ë¥  ê¸°ë°˜ ëŒ€í‘œ ìƒ˜í”Œ
probs = rf_top.predict_proba(X_top)[:, 1]

idx_high = np.argmax(probs)
idx_low  = np.argmin(probs)
idx_mid  = np.argsort(np.abs(probs - 0.5))[0]

sample_idx = [idx_high, idx_low, idx_mid]

# 2) Expected Value ê°€ì ¸ì˜¤ê¸°
ev = explainer.expected_value
if isinstance(ev, (list, np.ndarray)):
    expected_value_class1 = ev[1] if len(ev) > 1 else ev[0]
else:
    expected_value_class1 = ev

# 3) feature ì´ë¦„
feature_names = list(X_top.columns)

# ----------------------------------------------------------
# SHAP Decision Plot
# ----------------------------------------------------------
plt.figure(figsize=(14, 20), dpi=1200)

shap.decision_plot(
    expected_value_class1,
    shap_values_to_plot[sample_idx, :],
    feature_names=feature_names,
    legend_labels=[
        f"High (idx={idx_high})",
        f"Low (idx={idx_low})",
        f"Mid (idx={idx_mid})"
    ],
    legend_location="best",
    show=False
)

plt.tight_layout()
plt.savefig("shap_decision_plot_highres_fontlarge.png", dpi=1200)
plt.show()

